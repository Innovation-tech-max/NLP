{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPday3.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1CsJyH_sMJn"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uRviWqSPWQA"
      },
      "source": [
        "nltk.download('all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn0PU7mmYmoP"
      },
      "source": [
        "from nltk.book import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxZpm3cUXIS-"
      },
      "source": [
        "### Looping with conditions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE9dU6_oOicP"
      },
      "source": [
        "sent1=['Call','me','Mukut','.']\n",
        "for xyzzy in sent1:\n",
        "  if xyzzy.endswith('t'):\n",
        "    print(xyzzy)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT63M40DOvfJ"
      },
      "source": [
        "for token in sent1:\n",
        "  if token.islower():\n",
        "    print(token,'is lowercase.')\n",
        "  elif token.istitle():\n",
        "    print(token, 'is a titlecase word')\n",
        "else:\n",
        "  print(token, 'is punctuation')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71e5avS8XlSq"
      },
      "source": [
        "text2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhKSVLOzYkkw"
      },
      "source": [
        "tricky= sorted([w for w in set(text2) if \"cie\" in w or \"cei\" in w])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys_4RkGjZJie"
      },
      "source": [
        "for word in tricky:\n",
        "  print(word,end=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHPUbNKzjtzX"
      },
      "source": [
        "## Generating Language Output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UQhGlo5pipf"
      },
      "source": [
        "### babelize_shell() or babelfish translator service is gone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZVHBv3mrx5m"
      },
      "source": [
        "# **Gutenburg Corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-TLp_eFrrXF"
      },
      "source": [
        "nltk.corpus.gutenberg.fileids()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLrQc-Rqr7n2"
      },
      "source": [
        "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
        "len(emma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOtQq_fDsFCR"
      },
      "source": [
        "for fileid in gutenberg.fileids():\n",
        "  num_chars = len(gutenberg.raw(fileid))\n",
        "  num_words = len(gutenberg.words(fileid))\n",
        "  num_sents = len(gutenberg.sents(fileid))\n",
        "  num_vocab = len(set([w.lower() for w in gutenberg.words(fileid)]))\n",
        "print(int(num_chars/num_words), int(num_words/num_sents), int(num_words/num_vocab),fileid)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O4-uNhJtieH"
      },
      "source": [
        "len(gutenberg.raw('blake-poems.txt'))   #raw() gives us the contents of the file without any linguistic processing."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HskVoNDnscpf"
      },
      "source": [
        "macbeth_sentences = gutenberg.sents('shakespeare-macbeth.txt')\n",
        "macbeth_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HqVEPy3tEu3"
      },
      "source": [
        "longest_len = max([len(s) for s in macbeth_sentences])\n",
        "longest_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLGoLwLftRua"
      },
      "source": [
        "[s for s in macbeth_sentences if len(s) == longest_len]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhoOuPZRt2Iv"
      },
      "source": [
        "# Web and Chat Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5GiEdavtTEX"
      },
      "source": [
        "from nltk.corpus import webtext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMRIx5KLuAWw"
      },
      "source": [
        "for fileid in webtext.fileids():\n",
        "  print(fileid, webtext.raw(fileid)[:65])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epClVhHdufPE"
      },
      "source": [
        "from nltk.corpus import nps_chat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_K7Jdq2unNd"
      },
      "source": [
        "chatroom = nps_chat.posts('10-19-20s_706posts.xml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HILW-wh4vtVY"
      },
      "source": [
        "chatroom[123]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSDEonYoxhKd"
      },
      "source": [
        "# **Brown Corpus** : The Brown Corpus is a convenient resource for studying systematic differences between genres, a kind of linguistic inquiry known as stylistics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIzMTGFHwFwW"
      },
      "source": [
        "from nltk.corpus import brown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "354XGoxVxsGu"
      },
      "source": [
        "brown.categories()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX9XabVHxyMr"
      },
      "source": [
        "brown.words(categories='news')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnQJzGccx9Ga"
      },
      "source": [
        "brown.words(fileids='cg22')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCNCZTmcyEeX"
      },
      "source": [
        "brown.sents(categories=['news', 'editorial', 'reviews'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9kgn29qyHtt"
      },
      "source": [
        "news_text=brown.words(categories='news')\n",
        "fdist= nltk.FreqDist([w.lower() for w in news_text])\n",
        "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
        "for m in modals:\n",
        "  print(m + ':', fdist[m],end=(\",\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m7LZDvOyxRZ"
      },
      "source": [
        "editorial_text=brown.words(categories='editorial')\n",
        "fdist1=nltk.FreqDist([w.lower for w in editorial_text])\n",
        "modals1=['what', 'when','where', 'who','why']\n",
        "for m in modals1:\n",
        "  print(m+\":\",fdist1[m],end=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEqGnrLnz4OM"
      },
      "source": [
        "cfd = nltk.ConditionalFreqDist((genre, word)\n",
        "for genre in brown.categories()\n",
        "  for word in brown.words(categories=genre))\n",
        "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
        "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
        "cfd.tabulate(conditions=genres, samples=modals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjgTRqWb0kjv"
      },
      "source": [
        "Here, most frequent modal in the news genre is 'will', while the most frequent modal in the romance genre is 'could'."
      ]
    }
  ]
}